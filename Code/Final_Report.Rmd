---
title: 'Final Report'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(root.dir = normalizePath("C:/Users/wjhla/OneDrive/Documents/UMichigan/BIOSTAT 625/Final"))
```

```{r, echo=FALSE}
#suppressMessages(library(shiny))
suppressMessages(library(DT))
suppressMessages(library(ggplot2))
suppressMessages(library(ggpubr))
suppressMessages(library(tidyverse))
suppressMessages(library(dplyr))
suppressMessages(library(DescTools))
suppressMessages(library(PropCIs))
suppressMessages(library(qpcR))
suppressMessages(library(scales))
suppressMessages(library(kableExtra))
suppressMessages(library(broom))
suppressMessages(library(logistf))
suppressMessages(library(RColorBrewer))
suppressMessages(library(factoextra))
suppressMessages(library(psych))
suppressMessages(library(reshape2))
suppressMessages(library(e1071))
suppressMessages(library(rpart))
suppressMessages(library(rpart.plot))
suppressMessages(library(caret))
suppressMessages(library(glmnet))
suppressMessages(library(xgboost)) # the main algorithm # for the sample dataset 
suppressMessages((Ckmeans.1d.dp)) # for xgb.ggplot.importance
suppressMessages(library(performanceEstimation))

`%!in%` <- Negate(`%in%`)
```

## Read Data
```{r, echo=FALSE}
# Read original data
dataRDS = readRDS("Data/AllData_v20211213_1.rds")

# Data cleaning
dataRDS$DIQ010 = ifelse(dataRDS$DIQ010 %in% c(7,9), NA, dataRDS$DIQ010)
dataRDS = dataRDS[!is.na(dataRDS$DIQ010),]
dataRDS$DIQ010 = ifelse(dataRDS$DIQ010 == 3, 1, dataRDS$DIQ010)
dataRDS$DIQ010 = ifelse(dataRDS$DIQ010 == 2, 0, dataRDS$DIQ010)
table(dataRDS$DIQ010) # Extremely Unbalanced
dataRDS$DIQ010 = as.factor(dataRDS$DIQ010)
dataRDS = dataRDS[,-1]
```

```{r, echo = FALSE}
# Read Lasso Results
year = seq(1999, 2017,2)
namelist = paste("Lasso_glmnet_",rep("data",length(year)),year,rep("_",length(year)),year+1,sep = "")

# Store the results in tbl
tbl=c()
for(i in namelist){
  load(paste("Results/",i,".RData",sep = ""))
  tbl=rbind(tbl,result$result)
  assign(i,result)
  #eval(parse(text = paste0(i,"= temp")))
}

# Store the important variables
resultvarslasso = list()

for(i in namelist){
  tmp = get(i)
  resultvarslasso[[i]] = tmp$var
}

# Get the common variables
comvarlasso = unlist(resultvarslasso)
comvarlasso = sort(table(comvarlasso), decreasing = T)
comvarlasso = names(comvarlasso[comvarlasso>8])
```

## Xgboost
```{r, echo=FALSE}
year = seq(1999, 2017,2)
namelist = paste("Xgboost_",rep("data",length(year)),year,rep("_",length(year)),year+1,sep = "")

for(i in namelist){
  load(paste("Results/",i,".RData",sep = ""))
  tbl=rbind(tbl,result$result)
  assign(i,result)
  #eval(parse(text = paste0(i,"= temp")))
}

# Store the important variables
resultvarsxgboost = list()

for(i in namelist){
  tmp = get(i)
  resultvarsxgboost[[i]] = tmp$var
}

# Get the common variables
comvarxgboost = unlist(resultvarsxgboost)
comvarxgboost = sort(table(comvarxgboost), decreasing = T)
comvarxgboost = names(comvarxgboost[comvarxgboost>1])
```

## Combine 
```{r}
year = seq(1999,2017,2)
namelist = paste(rep("data",length(year)),year,rep("_",length(year)),year+1,sep = "")

# Store the important variables
yearvars= list()
for(i in namelist){
    temp = readRDS(paste("Data/",i,".rds",sep = ""))
    yearvars[[i]] = colnames(temp)
}
yearvars = unlist(yearvars)
yearvars = sort(table(yearvars), decreasing = T)

# Calculate variable percentage of frequencies and get the those appears more than 30% times
comvar1 = comvarxgboost/yearvars[names(yearvars)%in%names(comvarxgboost)]
comvar2 = comvarlasso/yearvars[names(yearvars)%in%names(comvarlasso)]
comvar1 = names(comvar1[comvar1>0.3])
comvar2 = names(comvar2[comvar2>0.3])

# Overlap
overlap = comvar2[comvar2 %in% comvar1]
# Remove "RIDAGEEX"
overlap = overlap[overlap %!in% c("RIDAGEEX","SDMVSTRA", "MCQ010")]

# Include response
overlap = c("DIQ010", overlap)


# Select the important variables obtained from Lasso
dataRDS=dataRDS[,colnames(dataRDS) %in% overlap]

# Remove those with lots of NA
miss = colSums(is.na(dataRDS))

dataRDS=dataRDS[,colnames(dataRDS) %in% names(miss[miss < 10000])]

# Complete cases
complete = dataRDS[complete.cases(dataRDS),]


# logistic regression
library(caret)
train.index = createDataPartition(complete$DIQ010, p = 0.6, list= FALSE)
train.data = complete[train.index ,]
train.data = smote(DIQ010~., train.data, perc.over = 20, perc.under = 1)
test.data = complete[-train.index,]

lmod = glm(DIQ010~.,data = train.data, family="binomial",maxit=50)


x.test = test.data[,which(colnames(test.data) != "DIQ010")]
probabilities = predict(lmod, newdata = x.test, type = "response")

predicted.classes = ifelse(probabilities > 0.5, 1, 0)

cm = confusionMatrix(factor(predicted.classes),test.data$DIQ010, positive = "1");cm

# Lasso
x <- model.matrix(DIQ010~., train.data)[,-1]
# Convert the outcome (DIQ010) to a numerical variable
y <- ifelse(train.data$DIQ010 == 1, 1, 0)
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")


# Fit the final model on the training data
model <- glmnet(x, y, alpha = 1, family = "binomial",
                lambda = cv.lasso$lambda.1se)

# Get sensitivity
x.test <- model.matrix(DIQ010~., test.data)[,-1]
probabilities <- model %>% predict(newx = x.test, type="response")

cutoffs = seq(0.01, 0.99, 0.01)
accus = c()
sensitivities = c()
specificities = c()
for (i in 1:length(cutoffs)) {
  predicted.classes <- ifelse(probabilities > cutoffs[i], 1, 0)
  cm.k <- confusionMatrix(factor(predicted.classes),test.data$DIQ010);cm.k
  accus = c(accus,cm.k$overall['Accuracy'])
  sensitivities = c(sensitivities, cm.k$byClass['Sensitivity'])
  specificities = c(specificities, cm.k$byClass['Specificity'])
}
euclid = sqrt((1-specificities)^2 + (sensitivities-1)^2)

predicted.classes <- ifelse(probabilities > cutoffs[which.min(euclid)], 1, 0)
# Model accuracy
cm = confusionMatrix(factor(predicted.classes),test.data$DIQ010, positive = "1");cm


# Xgboost
test.label = as.integer(test.data$DIQ010)-1
train.label = as.integer(train.data$DIQ010)-1
  
train.data <- data.frame(lapply(train.data, as.numeric))
test.data <- data.frame(lapply(test.data, as.numeric))

train.data$DIQ010 = NULL
train.data=as.matrix(train.data)

test.data$DIQ010 = NULL
test.data=as.matrix(test.data)

trainMatrix = xgb.DMatrix(data=train.data,label=train.label)
  testMatrix = xgb.DMatrix(data=test.data,label=test.label)
# Define the parameters
params = list(
  booster="gbtree",
  eta=0.001,
  max_depth=5,
  gamma=3,
  subsample=0.75,
  colsample_bytree=1,
  objective="binary:logistic",
  eval_metric="rmse"
)
# Train the XGBoost classifier
fit.xg=xgb.train(
  params=params,
  data=trainMatrix,
  nrounds=1000,
  
  early_stopping_rounds=10,
  watchlist=list(training=trainMatrix,testing=testMatrix),
  verbose=0
)
XGpred <- predict(fit.xg, newdata = testMatrix)
XGprediction <- as.numeric(XGpred>0.5)
# Use the predicted label with the highest probability
cmXG<-confusionMatrix(factor(XGprediction),
                      factor(test.label), positive = '1');cmXG
```
